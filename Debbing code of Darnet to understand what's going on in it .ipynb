{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import numpy as np\n",
    "import cv2 \n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cfg/yolov3.cfg\n"
     ]
    }
   ],
   "source": [
    "configFile = \"cfg/yolov3.cfg\"\n",
    "print(configFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='cfg/yolov3.cfg' mode='r' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "config = open(configFile,'r')   \n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = config.read().split('\\n')\n",
    "#print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[net]\n",
      "# Testing\n",
      "batch=1\n",
      "subdivisions=1\n",
      "# Training\n",
      "# batch=64\n",
      "# subdivisions=16\n",
      "width= 320\n",
      "height = 320\n",
      "channels=3\n",
      "momentum=0.9\n",
      "decay=0.0005\n",
      "angle=0\n",
      "saturation = 1.5\n",
      "exposure = 1.5\n",
      "hue=.1\n",
      "\n",
      "learning_rate=0.001\n",
      "burn_in=1000\n",
      "max_batches = 500200\n",
      "policy=steps\n",
      "steps=400000,450000\n",
      "scales=.1,.1\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=32\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "# Downsample\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=64\n",
      "size=3\n",
      "stride=2\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=32\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=64\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "# Downsample\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=3\n",
      "stride=2\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=64\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=64\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "#route\n",
      "\n",
      "# Downsample\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=3\n",
      "stride=2\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "# Downsample\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=3\n",
      "stride=2\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "# Downsample\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=1024\n",
      "size=3\n",
      "stride=2\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=1024\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=1024\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=1024\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=1024\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "######################\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "filters=1024\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "filters=1024\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "filters=1024\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "filters=255\n",
      "activation=linear\n",
      "\n",
      "\n",
      "[yolo]\n",
      "mask = 6,7,8\n",
      "anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326\n",
      "classes=80\n",
      "num=9\n",
      "jitter=.3\n",
      "ignore_thresh = .5\n",
      "truth_thresh = 1\n",
      "random=1\n",
      "\n",
      "\n",
      "[route]\n",
      "layers = -4\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[upsample]\n",
      "stride=2\n",
      "\n",
      "[route]\n",
      "layers = -1, 61\n",
      "\n",
      "\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "filters=512\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "filters=512\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "filters=512\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "filters=255\n",
      "activation=linear\n",
      "\n",
      "\n",
      "[yolo]\n",
      "mask = 3,4,5\n",
      "anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326\n",
      "classes=80\n",
      "num=9\n",
      "jitter=.3\n",
      "ignore_thresh = .5\n",
      "truth_thresh = 1\n",
      "random=1\n",
      "\n",
      "\n",
      "\n",
      "[route]\n",
      "layers = -4\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[upsample]\n",
      "stride=2\n",
      "\n",
      "[route]\n",
      "layers = -1, 36\n",
      "\n",
      "#yolo\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "filters=256\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "filters=256\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "filters=256\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "filters=255\n",
      "activation=linear\n",
      "\n",
      "\n",
      "[yolo]\n",
      "mask = 0,1,2\n",
      "anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326\n",
      "classes=80\n",
      "num=9\n",
      "jitter=.3\n",
      "ignore_thresh = .5\n",
      "truth_thresh = 1\n",
      "random=1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in file:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = [line for line in file if len(line) > 0 and line[0]!= '#']\n",
    "#print(file )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = [line.lstrip().rstrip() for line in file]\n",
    "#print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "networkBlocks = [] \n",
    "print(networkBlocks)\n",
    "networkBlock = {}\n",
    "print(networkBlock )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[net]\n",
      "[\n",
      "batch=1\n",
      "b\n",
      "subdivisions=1\n",
      "s\n",
      "width= 320\n",
      "w\n",
      "height = 320\n",
      "h\n",
      "channels=3\n",
      "c\n",
      "momentum=0.9\n",
      "m\n",
      "decay=0.0005\n",
      "d\n",
      "angle=0\n",
      "a\n",
      "saturation = 1.5\n",
      "s\n",
      "exposure = 1.5\n",
      "e\n",
      "hue=.1\n",
      "h\n",
      "learning_rate=0.001\n",
      "l\n",
      "burn_in=1000\n",
      "b\n",
      "max_batches = 500200\n",
      "m\n",
      "policy=steps\n",
      "p\n",
      "steps=400000,450000\n",
      "s\n",
      "scales=.1,.1\n",
      "s\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=32\n",
      "f\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=64\n",
      "f\n",
      "size=3\n",
      "s\n",
      "stride=2\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=32\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=64\n",
      "f\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[shortcut]\n",
      "[\n",
      "from=-3\n",
      "f\n",
      "activation=linear\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=128\n",
      "f\n",
      "size=3\n",
      "s\n",
      "stride=2\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=64\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=128\n",
      "f\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[shortcut]\n",
      "[\n",
      "from=-3\n",
      "f\n",
      "activation=linear\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=64\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=128\n",
      "f\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[shortcut]\n",
      "[\n",
      "from=-3\n",
      "f\n",
      "activation=linear\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=256\n",
      "f\n",
      "size=3\n",
      "s\n",
      "stride=2\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=128\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=256\n",
      "f\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[shortcut]\n",
      "[\n",
      "from=-3\n",
      "f\n",
      "activation=linear\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=128\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=256\n",
      "f\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[shortcut]\n",
      "[\n",
      "from=-3\n",
      "f\n",
      "activation=linear\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=128\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=256\n",
      "f\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[shortcut]\n",
      "[\n",
      "from=-3\n",
      "f\n",
      "activation=linear\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=128\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=256\n",
      "f\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[shortcut]\n",
      "[\n",
      "from=-3\n",
      "f\n",
      "activation=linear\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=128\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=256\n",
      "f\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[shortcut]\n",
      "[\n",
      "from=-3\n",
      "f\n",
      "activation=linear\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=128\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=256\n",
      "f\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[shortcut]\n",
      "[\n",
      "from=-3\n",
      "f\n",
      "activation=linear\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=128\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=256\n",
      "f\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[shortcut]\n",
      "[\n",
      "from=-3\n",
      "f\n",
      "activation=linear\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=128\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=256\n",
      "f\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[shortcut]\n",
      "[\n",
      "from=-3\n",
      "f\n",
      "activation=linear\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=512\n",
      "f\n",
      "size=3\n",
      "s\n",
      "stride=2\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=256\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=512\n",
      "f\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[shortcut]\n",
      "[\n",
      "from=-3\n",
      "f\n",
      "activation=linear\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=256\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=512\n",
      "f\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[shortcut]\n",
      "[\n",
      "from=-3\n",
      "f\n",
      "activation=linear\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=256\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=512\n",
      "f\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[shortcut]\n",
      "[\n",
      "from=-3\n",
      "f\n",
      "activation=linear\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=256\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=512\n",
      "f\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[shortcut]\n",
      "[\n",
      "from=-3\n",
      "f\n",
      "activation=linear\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=256\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=512\n",
      "f\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[shortcut]\n",
      "[\n",
      "from=-3\n",
      "f\n",
      "activation=linear\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=256\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=512\n",
      "f\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[shortcut]\n",
      "[\n",
      "from=-3\n",
      "f\n",
      "activation=linear\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=256\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=512\n",
      "f\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[shortcut]\n",
      "[\n",
      "from=-3\n",
      "f\n",
      "activation=linear\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=256\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=512\n",
      "f\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[shortcut]\n",
      "[\n",
      "from=-3\n",
      "f\n",
      "activation=linear\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=1024\n",
      "f\n",
      "size=3\n",
      "s\n",
      "stride=2\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=512\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=1024\n",
      "f\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[shortcut]\n",
      "[\n",
      "from=-3\n",
      "f\n",
      "activation=linear\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=512\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=1024\n",
      "f\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[shortcut]\n",
      "[\n",
      "from=-3\n",
      "f\n",
      "activation=linear\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=512\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=1024\n",
      "f\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[shortcut]\n",
      "[\n",
      "from=-3\n",
      "f\n",
      "activation=linear\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=512\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=1024\n",
      "f\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[shortcut]\n",
      "[\n",
      "from=-3\n",
      "f\n",
      "activation=linear\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=512\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "filters=1024\n",
      "f\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=512\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "filters=1024\n",
      "f\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=512\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "filters=1024\n",
      "f\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "filters=255\n",
      "f\n",
      "activation=linear\n",
      "a\n",
      "[yolo]\n",
      "[\n",
      "mask = 6,7,8\n",
      "m\n",
      "anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326\n",
      "a\n",
      "classes=80\n",
      "c\n",
      "num=9\n",
      "n\n",
      "jitter=.3\n",
      "j\n",
      "ignore_thresh = .5\n",
      "i\n",
      "truth_thresh = 1\n",
      "t\n",
      "random=1\n",
      "r\n",
      "[route]\n",
      "[\n",
      "layers = -4\n",
      "l\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=256\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[upsample]\n",
      "[\n",
      "stride=2\n",
      "s\n",
      "[route]\n",
      "[\n",
      "layers = -1, 61\n",
      "l\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=256\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "filters=512\n",
      "f\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=256\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "filters=512\n",
      "f\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=256\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "filters=512\n",
      "f\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "filters=255\n",
      "f\n",
      "activation=linear\n",
      "a\n",
      "[yolo]\n",
      "[\n",
      "mask = 3,4,5\n",
      "m\n",
      "anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326\n",
      "a\n",
      "classes=80\n",
      "c\n",
      "num=9\n",
      "n\n",
      "jitter=.3\n",
      "j\n",
      "ignore_thresh = .5\n",
      "i\n",
      "truth_thresh = 1\n",
      "t\n",
      "random=1\n",
      "r\n",
      "[route]\n",
      "[\n",
      "layers = -4\n",
      "l\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=128\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[upsample]\n",
      "[\n",
      "stride=2\n",
      "s\n",
      "[route]\n",
      "[\n",
      "layers = -1, 36\n",
      "l\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=128\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "filters=256\n",
      "f\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=128\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "filters=256\n",
      "f\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "filters=128\n",
      "f\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "batch_normalize=1\n",
      "b\n",
      "size=3\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "filters=256\n",
      "f\n",
      "activation=leaky\n",
      "a\n",
      "[convolutional]\n",
      "[\n",
      "size=1\n",
      "s\n",
      "stride=1\n",
      "s\n",
      "pad=1\n",
      "p\n",
      "filters=255\n",
      "f\n",
      "activation=linear\n",
      "a\n",
      "[yolo]\n",
      "[\n",
      "mask = 0,1,2\n",
      "m\n",
      "anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326\n",
      "a\n",
      "classes=80\n",
      "c\n",
      "num=9\n",
      "n\n",
      "jitter=.3\n",
      "j\n",
      "ignore_thresh = .5\n",
      "i\n",
      "truth_thresh = 1\n",
      "t\n",
      "random=1\n",
      "r\n"
     ]
    }
   ],
   "source": [
    " for x in file:\n",
    "        print(x)\n",
    "        a = x[0]\n",
    "        print(a)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "configFile = \"cfg/yolov3.cfg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = open(configFile,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[net]', '# Testing', 'batch=1', 'subdivisions=1', '# Training', '# batch=64', '# subdivisions=16', 'width= 320', 'height = 320', 'channels=3', 'momentum=0.9', 'decay=0.0005', 'angle=0', 'saturation = 1.5', 'exposure = 1.5', 'hue=.1', '', 'learning_rate=0.001', 'burn_in=1000', 'max_batches = 500200', 'policy=steps', 'steps=400000,450000', 'scales=.1,.1', '', '[convolutional]', 'batch_normalize=1', 'filters=32', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '', '# Downsample', '', '[convolutional]', 'batch_normalize=1', 'filters=64', 'size=3', 'stride=2', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=32', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=64', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '', '[shortcut]', 'from=-3', 'activation=linear', '', '# Downsample', '', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=3', 'stride=2', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=64', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '', '[shortcut]', 'from=-3', 'activation=linear', '', '[convolutional]', 'batch_normalize=1', 'filters=64', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '', '[shortcut]', 'from=-3', 'activation=linear', '', '#route', '', '# Downsample', '', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=3', 'stride=2', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '', '[shortcut]', 'from=-3', 'activation=linear', '', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '', '[shortcut]', 'from=-3', 'activation=linear', '', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '', '[shortcut]', 'from=-3', 'activation=linear', '', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '', '[shortcut]', 'from=-3', 'activation=linear', '', '', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '', '[shortcut]', 'from=-3', 'activation=linear', '', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '', '[shortcut]', 'from=-3', 'activation=linear', '', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '', '[shortcut]', 'from=-3', 'activation=linear', '', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '', '[shortcut]', 'from=-3', 'activation=linear', '', '# Downsample', '', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=3', 'stride=2', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '', '[shortcut]', 'from=-3', 'activation=linear', '', '', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '', '[shortcut]', 'from=-3', 'activation=linear', '', '', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '', '[shortcut]', 'from=-3', 'activation=linear', '', '', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '', '[shortcut]', 'from=-3', 'activation=linear', '', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '', '[shortcut]', 'from=-3', 'activation=linear', '', '', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '', '[shortcut]', 'from=-3', 'activation=linear', '', '', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '', '[shortcut]', 'from=-3', 'activation=linear', '', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '', '[shortcut]', 'from=-3', 'activation=linear', '', '# Downsample', '', '[convolutional]', 'batch_normalize=1', 'filters=1024', 'size=3', 'stride=2', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=1024', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '', '[shortcut]', 'from=-3', 'activation=linear', '', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=1024', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '', '[shortcut]', 'from=-3', 'activation=linear', '', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=1024', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '', '[shortcut]', 'from=-3', 'activation=linear', '', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=1024', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '', '[shortcut]', 'from=-3', 'activation=linear', '', '######################', '', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'size=3', 'stride=1', 'pad=1', 'filters=1024', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'size=3', 'stride=1', 'pad=1', 'filters=1024', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'size=3', 'stride=1', 'pad=1', 'filters=1024', 'activation=leaky', '', '[convolutional]', 'size=1', 'stride=1', 'pad=1', 'filters=255', 'activation=linear', '', '', '[yolo]', 'mask = 6,7,8', 'anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326', 'classes=80', 'num=9', 'jitter=.3', 'ignore_thresh = .5', 'truth_thresh = 1', 'random=1', '', '', '[route]', 'layers = -4', '', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[upsample]', 'stride=2', '', '[route]', 'layers = -1, 61', '', '', '', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'size=3', 'stride=1', 'pad=1', 'filters=512', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'size=3', 'stride=1', 'pad=1', 'filters=512', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'size=3', 'stride=1', 'pad=1', 'filters=512', 'activation=leaky', '', '[convolutional]', 'size=1', 'stride=1', 'pad=1', 'filters=255', 'activation=linear', '', '', '[yolo]', 'mask = 3,4,5', 'anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326', 'classes=80', 'num=9', 'jitter=.3', 'ignore_thresh = .5', 'truth_thresh = 1', 'random=1', '', '', '', '[route]', 'layers = -4', '', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[upsample]', 'stride=2', '', '[route]', 'layers = -1, 36', '', '#yolo', '', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'size=3', 'stride=1', 'pad=1', 'filters=256', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'size=3', 'stride=1', 'pad=1', 'filters=256', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '', '[convolutional]', 'batch_normalize=1', 'size=3', 'stride=1', 'pad=1', 'filters=256', 'activation=leaky', '', '[convolutional]', 'size=1', 'stride=1', 'pad=1', 'filters=255', 'activation=linear', '', '', '[yolo]', 'mask = 0,1,2', 'anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326', 'classes=80', 'num=9', 'jitter=.3', 'ignore_thresh = .5', 'truth_thresh = 1', 'random=1', '', '']\n"
     ]
    }
   ],
   "source": [
    "file = config.read().split('\\n')\n",
    "print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[net]', 'batch=1', 'subdivisions=1', 'width= 320', 'height = 320', 'channels=3', 'momentum=0.9', 'decay=0.0005', 'angle=0', 'saturation = 1.5', 'exposure = 1.5', 'hue=.1', 'learning_rate=0.001', 'burn_in=1000', 'max_batches = 500200', 'policy=steps', 'steps=400000,450000', 'scales=.1,.1', '[convolutional]', 'batch_normalize=1', 'filters=32', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=64', 'size=3', 'stride=2', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=32', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=64', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=3', 'stride=2', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=64', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=64', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=3', 'stride=2', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=3', 'stride=2', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=1024', 'size=3', 'stride=2', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=1024', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=1024', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=1024', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=1024', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'size=3', 'stride=1', 'pad=1', 'filters=1024', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'size=3', 'stride=1', 'pad=1', 'filters=1024', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'size=3', 'stride=1', 'pad=1', 'filters=1024', 'activation=leaky', '[convolutional]', 'size=1', 'stride=1', 'pad=1', 'filters=255', 'activation=linear', '[yolo]', 'mask = 6,7,8', 'anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326', 'classes=80', 'num=9', 'jitter=.3', 'ignore_thresh = .5', 'truth_thresh = 1', 'random=1', '[route]', 'layers = -4', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[upsample]', 'stride=2', '[route]', 'layers = -1, 61', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'size=3', 'stride=1', 'pad=1', 'filters=512', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'size=3', 'stride=1', 'pad=1', 'filters=512', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'size=3', 'stride=1', 'pad=1', 'filters=512', 'activation=leaky', '[convolutional]', 'size=1', 'stride=1', 'pad=1', 'filters=255', 'activation=linear', '[yolo]', 'mask = 3,4,5', 'anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326', 'classes=80', 'num=9', 'jitter=.3', 'ignore_thresh = .5', 'truth_thresh = 1', 'random=1', '[route]', 'layers = -4', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[upsample]', 'stride=2', '[route]', 'layers = -1, 36', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'size=3', 'stride=1', 'pad=1', 'filters=256', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'size=3', 'stride=1', 'pad=1', 'filters=256', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'size=3', 'stride=1', 'pad=1', 'filters=256', 'activation=leaky', '[convolutional]', 'size=1', 'stride=1', 'pad=1', 'filters=255', 'activation=linear', '[yolo]', 'mask = 0,1,2', 'anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326', 'classes=80', 'num=9', 'jitter=.3', 'ignore_thresh = .5', 'truth_thresh = 1', 'random=1']\n"
     ]
    }
   ],
   "source": [
    "file = [line for line in file if len(line) > 0 and line[0]!= '#']\n",
    "print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[net]', 'batch=1', 'subdivisions=1', 'width= 320', 'height = 320', 'channels=3', 'momentum=0.9', 'decay=0.0005', 'angle=0', 'saturation = 1.5', 'exposure = 1.5', 'hue=.1', 'learning_rate=0.001', 'burn_in=1000', 'max_batches = 500200', 'policy=steps', 'steps=400000,450000', 'scales=.1,.1', '[convolutional]', 'batch_normalize=1', 'filters=32', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=64', 'size=3', 'stride=2', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=32', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=64', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=3', 'stride=2', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=64', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=64', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=3', 'stride=2', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=3', 'stride=2', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=1024', 'size=3', 'stride=2', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=1024', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=1024', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=1024', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=1024', 'size=3', 'stride=1', 'pad=1', 'activation=leaky', '[shortcut]', 'from=-3', 'activation=linear', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'size=3', 'stride=1', 'pad=1', 'filters=1024', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'size=3', 'stride=1', 'pad=1', 'filters=1024', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=512', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'size=3', 'stride=1', 'pad=1', 'filters=1024', 'activation=leaky', '[convolutional]', 'size=1', 'stride=1', 'pad=1', 'filters=255', 'activation=linear', '[yolo]', 'mask = 6,7,8', 'anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326', 'classes=80', 'num=9', 'jitter=.3', 'ignore_thresh = .5', 'truth_thresh = 1', 'random=1', '[route]', 'layers = -4', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[upsample]', 'stride=2', '[route]', 'layers = -1, 61', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'size=3', 'stride=1', 'pad=1', 'filters=512', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'size=3', 'stride=1', 'pad=1', 'filters=512', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=256', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'size=3', 'stride=1', 'pad=1', 'filters=512', 'activation=leaky', '[convolutional]', 'size=1', 'stride=1', 'pad=1', 'filters=255', 'activation=linear', '[yolo]', 'mask = 3,4,5', 'anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326', 'classes=80', 'num=9', 'jitter=.3', 'ignore_thresh = .5', 'truth_thresh = 1', 'random=1', '[route]', 'layers = -4', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[upsample]', 'stride=2', '[route]', 'layers = -1, 36', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'size=3', 'stride=1', 'pad=1', 'filters=256', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'size=3', 'stride=1', 'pad=1', 'filters=256', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'filters=128', 'size=1', 'stride=1', 'pad=1', 'activation=leaky', '[convolutional]', 'batch_normalize=1', 'size=3', 'stride=1', 'pad=1', 'filters=256', 'activation=leaky', '[convolutional]', 'size=1', 'stride=1', 'pad=1', 'filters=255', 'activation=linear', '[yolo]', 'mask = 0,1,2', 'anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326', 'classes=80', 'num=9', 'jitter=.3', 'ignore_thresh = .5', 'truth_thresh = 1', 'random=1']\n"
     ]
    }
   ],
   "source": [
    "file = [line.lstrip().rstrip() for line in file]\n",
    "print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "b\n",
      "s\n",
      "w\n",
      "h\n",
      "c\n",
      "m\n",
      "d\n",
      "a\n",
      "s\n",
      "e\n",
      "h\n",
      "l\n",
      "b\n",
      "m\n",
      "p\n",
      "s\n",
      "s\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "f\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "f\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "f\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "f\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "f\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "f\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "f\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "f\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "f\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "f\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "f\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "f\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "f\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "f\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "f\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "f\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "f\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "f\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "f\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "f\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "f\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "f\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "f\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "s\n",
      "s\n",
      "p\n",
      "f\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "s\n",
      "s\n",
      "p\n",
      "f\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "s\n",
      "s\n",
      "p\n",
      "f\n",
      "a\n",
      "[\n",
      "s\n",
      "s\n",
      "p\n",
      "f\n",
      "a\n",
      "[\n",
      "m\n",
      "a\n",
      "c\n",
      "n\n",
      "j\n",
      "i\n",
      "t\n",
      "r\n",
      "[\n",
      "l\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "s\n",
      "[\n",
      "l\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "s\n",
      "s\n",
      "p\n",
      "f\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "s\n",
      "s\n",
      "p\n",
      "f\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "s\n",
      "s\n",
      "p\n",
      "f\n",
      "a\n",
      "[\n",
      "s\n",
      "s\n",
      "p\n",
      "f\n",
      "a\n",
      "[\n",
      "m\n",
      "a\n",
      "c\n",
      "n\n",
      "j\n",
      "i\n",
      "t\n",
      "r\n",
      "[\n",
      "l\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "s\n",
      "[\n",
      "l\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "s\n",
      "s\n",
      "p\n",
      "f\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "s\n",
      "s\n",
      "p\n",
      "f\n",
      "a\n",
      "[\n",
      "b\n",
      "f\n",
      "s\n",
      "s\n",
      "p\n",
      "a\n",
      "[\n",
      "b\n",
      "s\n",
      "s\n",
      "p\n",
      "f\n",
      "a\n",
      "[\n",
      "s\n",
      "s\n",
      "p\n",
      "f\n",
      "a\n",
      "[\n",
      "m\n",
      "a\n",
      "c\n",
      "n\n",
      "j\n",
      "i\n",
      "t\n",
      "r\n"
     ]
    }
   ],
   "source": [
    "for x in file:\n",
    "    a = x[0] #== '['\n",
    "    for i in a:\n",
    "        b = len(a) != 0\n",
    "    print(a)\n",
    "    c = networkBlocks.append(networkBlock)\n",
    "    networkBlock = {}\n",
    "    networkBlock[\"type\"] = x[1:-1].rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "shortcut %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "shortcut %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "shortcut %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "shortcut %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "shortcut %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "shortcut %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "shortcut %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "shortcut %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "shortcut %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "shortcut %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "shortcut %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "shortcut %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "shortcut %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "shortcut %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "shortcut %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "shortcut %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "shortcut %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "shortcut %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "shortcut %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "shortcut %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "shortcut %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "shortcut %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "shortcut %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "yolo %%%%%%%%%%%%%%\n",
      "route %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "upsample %%%%%%%%%%%%%%\n",
      "route %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "yolo %%%%%%%%%%%%%%\n",
      "route %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "upsample %%%%%%%%%%%%%%\n",
      "route %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "convolutional %%%%%%%%%%%%%%\n",
      "yolo %%%%%%%%%%%%%%\n"
     ]
    }
   ],
   "source": [
    "    config = open(configFile,'r')\n",
    "    file = config.read().split('\\n')\n",
    "    \n",
    "    file = [line for line in file if len(line) > 0 and line[0]!= '#']\n",
    "    file = [line.lstrip().rstrip() for line in file]\n",
    "    \n",
    "    \n",
    "    #Separate network blocks in a list \n",
    "    \n",
    "    networkBlocks = []\n",
    "    \n",
    "    networkBlock = {}\n",
    "    \n",
    "    for x in file:\n",
    "        if x[0] == '[':\n",
    "            if len(networkBlock) != 0: # if [ is first letter we understand new layer is started [convolutional]\n",
    "                networkBlocks.append(networkBlock)\n",
    "                t = networkBlock = {}\n",
    "            k = networkBlock[\"type\"] = x[1:-1].rstrip()\n",
    "            print(k,\"%%%%%%%%%%%%%%\")\n",
    "        else:\n",
    "            entity , value = x.split('=')\n",
    "            \n",
    "            #print(entity,\"$$$$$$$$$$$$$$\")\n",
    "            #print(value,\"**********\")\n",
    "            s = networkBlock[entity.rstrip()] = value.lstrip()\n",
    "            #print(s)\n",
    "    j = networkBlocks.append(networkBlock)\n",
    "    #print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolo\n"
     ]
    }
   ],
   "source": [
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in file:\n",
    "    d = x[1:-1].rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "andom=\n"
     ]
    }
   ],
   "source": [
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'yolo', 'mask': '0,1,2', 'anchors': '10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326', 'classes': '80', 'num': '9', 'jitter': '.3', 'ignore_thresh': '.5', 'truth_thresh': '1', 'random': '1'}\n"
     ]
    }
   ],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random\n"
     ]
    }
   ],
   "source": [
    "print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '32', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n"
     ]
    }
   ],
   "source": [
    "    DNInfo = networkBlocks[1]\n",
    "    print(DNInfo)\n",
    "    modules = nn.ModuleList([])\n",
    "    #print(modules)\n",
    "    channels = 3\n",
    "    filterTracker = [] \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'net', 'batch': '1', 'subdivisions': '1', 'width': '320', 'height': '320', 'channels': '3', 'momentum': '0.9', 'decay': '0.0005', 'angle': '0', 'saturation': '1.5', 'exposure': '1.5', 'hue': '.1', 'learning_rate': '0.001', 'burn_in': '1000', 'max_batches': '500200', 'policy': 'steps', 'steps': '400000,450000', 'scales': '.1,.1'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '32', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '64', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '32', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '64', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '64', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '64', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '1024', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '1024', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '1024', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '1024', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '1024', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'shortcut', 'from': '-3', 'activation': 'linear'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '1024', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '1024', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '1024', 'activation': 'leaky'}, {'type': 'convolutional', 'size': '1', 'stride': '1', 'pad': '1', 'filters': '255', 'activation': 'linear'}, {'type': 'yolo', 'mask': '6,7,8', 'anchors': '10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326', 'classes': '80', 'num': '9', 'jitter': '.3', 'ignore_thresh': '.5', 'truth_thresh': '1', 'random': '1'}, {'type': 'route', 'layers': '-4'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'upsample', 'stride': '2'}, {'type': 'route', 'layers': '-1, 61'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '512', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '512', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '512', 'activation': 'leaky'}, {'type': 'convolutional', 'size': '1', 'stride': '1', 'pad': '1', 'filters': '255', 'activation': 'linear'}, {'type': 'yolo', 'mask': '3,4,5', 'anchors': '10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326', 'classes': '80', 'num': '9', 'jitter': '.3', 'ignore_thresh': '.5', 'truth_thresh': '1', 'random': '1'}, {'type': 'route', 'layers': '-4'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'upsample', 'stride': '2'}, {'type': 'route', 'layers': '-1, 36'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '256', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '256', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}, {'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '256', 'activation': 'leaky'}, {'type': 'convolutional', 'size': '1', 'stride': '1', 'pad': '1', 'filters': '255', 'activation': 'linear'}, {'type': 'yolo', 'mask': '0,1,2', 'anchors': '10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326', 'classes': '80', 'num': '9', 'jitter': '.3', 'ignore_thresh': '.5', 'truth_thresh': '1', 'random': '1'}]\n"
     ]
    }
   ],
   "source": [
    "print(networkBlocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '32', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '64', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '32', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '64', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '64', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '64', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '1024', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '1024', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '1024', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '1024', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '1024', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '1024', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '1024', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '1024', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'size': '1', 'stride': '1', 'pad': '1', 'filters': '255', 'activation': 'linear'}\n",
      "{'type': 'yolo', 'mask': '6,7,8', 'anchors': '10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326', 'classes': '80', 'num': '9', 'jitter': '.3', 'ignore_thresh': '.5', 'truth_thresh': '1', 'random': '1'}\n",
      "{'type': 'route', 'layers': '-4'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'upsample', 'stride': '2'}\n",
      "{'type': 'route', 'layers': '-1, 61'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '512', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '512', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '512', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'size': '1', 'stride': '1', 'pad': '1', 'filters': '255', 'activation': 'linear'}\n",
      "{'type': 'yolo', 'mask': '3,4,5', 'anchors': '10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326', 'classes': '80', 'num': '9', 'jitter': '.3', 'ignore_thresh': '.5', 'truth_thresh': '1', 'random': '1'}\n",
      "{'type': 'route', 'layers': '-4'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'upsample', 'stride': '2'}\n",
      "{'type': 'route', 'layers': '-1, 36'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '256', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '256', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '256', 'activation': 'leaky'}\n",
      "{'type': 'convolutional', 'size': '1', 'stride': '1', 'pad': '1', 'filters': '255', 'activation': 'linear'}\n",
      "{'type': 'yolo', 'mask': '0,1,2', 'anchors': '10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326', 'classes': '80', 'num': '9', 'jitter': '.3', 'ignore_thresh': '.5', 'truth_thresh': '1', 'random': '1'}\n"
     ]
    }
   ],
   "source": [
    "for i,x in enumerate(networkBlocks[1:]):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n",
      "convolutional\n"
     ]
    }
   ],
   "source": [
    "for i,x in enumerate(networkBlocks[1:]):\n",
    "\n",
    "    seqModule  = nn.Sequential()\n",
    "    if (x[\"type\"] == \"convolutional\"):\n",
    "        print( x[\"type\"])\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,x in enumerate(networkBlocks[1:]):\n",
    "        seqModule  = nn.Sequential()\n",
    "        #print(filters)\n",
    "        #print(pad)\n",
    "        #print(kernelSize)\n",
    "        #print(stride)\n",
    "        if (x[\"type\"] == \"convolutional\"):\n",
    "\n",
    "            filters= int(x[\"filters\"])\n",
    "            pad = int(x[\"pad\"])\n",
    "            kernelSize = int(x[\"size\"])\n",
    "            stride = int(x[\"stride\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dummyLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(dummyLayer, self).__init__()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class detector(nn.Module):\n",
    "    def __init__(self, anchors):\n",
    "        super(detector, self).__init__()\n",
    "        self.anchors = anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,x in enumerate(networkBlocks[1:]):\n",
    "        seqModule  = nn.Sequential()\n",
    "        if (x[\"type\"] == \"convolutional\"):\n",
    "\n",
    "            filters= int(x[\"filters\"])\n",
    "            pad = int(x[\"pad\"])\n",
    "            kernelSize = int(x[\"size\"])\n",
    "            stride = int(x[\"stride\"])\n",
    "\n",
    "            if pad:\n",
    "                padding = (kernelSize - 1) // 2\n",
    "            else:\n",
    "                padding = 0\n",
    "            \n",
    "            activation = x[\"activation\"]\n",
    "            try:\n",
    "                bn = int(x[\"batch_normalize\"])\n",
    "                bias = False\n",
    "            except:\n",
    "                bn = 0\n",
    "                bias = True\n",
    "\n",
    "            conv = nn.Conv2d(channels, filters, kernelSize, stride, padding, bias = bias)\n",
    "            seqModule.add_module(\"conv_{0}\".format(i), conv)\n",
    "\n",
    "            if bn:\n",
    "                bn = nn.BatchNorm2d(filters)\n",
    "                seqModule.add_module(\"batch_norm_{0}\".format(i), bn)\n",
    "\n",
    "            if activation == \"leaky\":\n",
    "                activn = nn.LeakyReLU(0.1, inplace = True)\n",
    "                seqModule.add_module(\"leaky_{0}\".format(i), activn)\n",
    "\n",
    "\n",
    "        elif (x[\"type\"] == \"upsample\"):\n",
    "            upsample = nn.Upsample(scale_factor = 2, mode = \"bilinear\")\n",
    "            seqModule.add_module(\"upsample_{}\".format(i), upsample)\n",
    "        \n",
    "        elif (x[\"type\"] == \"route\"):\n",
    "            x['layers'] = x[\"layers\"].split(',')\n",
    "            start = int(x['layers'][0])\n",
    "            try:\n",
    "                end = int(x['layers'][1])\n",
    "            except:\n",
    "                end =0\n",
    "            \n",
    "            if start > 0:\n",
    "                start = start - i \n",
    "            if end > 0:\n",
    "                end = end - i\n",
    "            \n",
    "            route = dummyLayer()\n",
    "            seqModule.add_module(\"route_{0}\".format(i),route)\n",
    "            if end < 0:\n",
    "                filters = filterTracker[i+start] + filterTracker[i+end]\n",
    "            else:\n",
    "                filters = filterTracker[i+start]\n",
    "        elif (x[\"type\"] == \"shortcut\"):\n",
    "            shortcut = dummyLayer()\n",
    "            seqModule.add_module(\"shortcut_{0}\".format(i),shortcut)\n",
    "        elif (x[\"type\"] == \"yolo\"):\n",
    "            anchors = x[\"anchors\"].split(',')\n",
    "            anchors = [int(a) for a in anchors]\n",
    "            masks = x[\"mask\"].split(',')\n",
    "            masks = [int(a) for a in masks]\n",
    "            anchors = [(anchors[j],anchors[j+1]) for j in range(0,len(anchors),2)]\n",
    "            anchors = [anchors[j] for j in masks]\n",
    "            detectorLayer = detector(anchors)\n",
    "\n",
    "            seqModule.add_module(\"Detection_{0}\".format(i),detectorLayer)\n",
    "        \n",
    "        modules.append(seqModule)\n",
    "        channels = filters\n",
    "        filterTracker.append(filters)\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
